{"prompt_id": "seed", "prompt": "Please act as an impartial judge and evaluate the quality of the responses provided by two AI assistants to the user question displayed below. You should choose the assistant that follows the user's instructions and answers the user's question better. Your evaluation should consider factors such as the helpfulness, relevance, accuracy, depth, creativity, and level of detail of their responses. Begin your evaluation by comparing the two responses and provide a short explanation. Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision. Do not allow the length of the responses to influence your evaluation. Do not favor certain names of the assistants. Be as objective as possible. After providing your explanation, output your final verdict by strictly following this format: \"[[A]]\" if assistant A is better, \"[[B]]\" if assistant B is better.\n\n[User Question]\n{instruction}\n\n[The Start of Assistant A's Answer]\n{answer_a}\n[The End of Assistant A's Answer]\n\n[The Start of Assistant B's Answer]\n{answer_b}\n[The End of Assistant B's Answer]\n"}
{"prompt_id": "step3_7_2", "parent_prompt_id": "seed", "gen_step": 3, "prompt": "You are an impartial judge evaluating two AI responses to a user instruction. Your task is to determine which response is better according to the criteria below. You must output your final verdict as either [[A]] or [[B]].\n\n**Evaluation Criteria**\n1.  **Instruction Compliance:** Does the response follow all explicit and implicit instructions? Does it fulfill the exact task requested?\n2.  **Accuracy & Correctness:** Is the information factually correct, logically sound, and free of major errors?\n3.  **Helpfulness & Completeness:** Does the response fully address the query? Is it useful and actionable without unnecessary fluff or omission of key details?\n4.  **Clarity & Conciseness:** Is the response well-organized and easy to understand? Is it direct and avoids redundant or irrelevant information?\n\n**Critical Guidelines**\n- **Directness Over Exposition:** Favor responses that get straight to the point. Extra context, unsolicited explanations, or verbose framing (e.g., \"Sure, I'd be happy to help!\") should be penalized unless the instruction explicitly asks for them.\n- **Task-First Evaluation:** Begin by identifying the core task. The best response is the one that most effectively and efficiently accomplishes that specific task.\n- **Avoid Bias:** Do not favor longer responses. Do not assume detailed creativity is required unless the instruction asks for it. Do not be influenced by the order of responses (A vs. B).\n- **Tie-Breaking:** If both responses are nearly equal, choose the one that is more concise and directly tailored to the instruction.\n\n**Output Format**\n1.  First, provide a brief comparative analysis referencing the criteria.\n2.  Then, on a new line, output your final verdict as either **[[A]]** or **[[B]]**.\n\n---\n**User Instruction:**\n{instruction}\n\n**Response A:**\n{answer_a}\n\n**Response B:**\n{answer_b}\n\n---\nBegin your evaluation."}
